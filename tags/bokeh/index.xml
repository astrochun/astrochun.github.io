<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bokeh | Chun Ly</title>
    <link>https://astrochun.github.io/tags/bokeh/</link>
      <atom:link href="https://astrochun.github.io/tags/bokeh/index.xml" rel="self" type="application/rss+xml" />
    <description>bokeh</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>MIT License</copyright><lastBuildDate>Sun, 11 Jul 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://astrochun.github.io/img/icon-192.png</url>
      <title>bokeh</title>
      <link>https://astrochun.github.io/tags/bokeh/</link>
    </image>
    
    <item>
      <title>Building a streamlit app to serve UArizona salary data and deploying it on Heroku</title>
      <link>https://astrochun.github.io/post/salary_app/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://astrochun.github.io/post/salary_app/</guid>
      <description>&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.wildcat.arizona.edu/&#34;&gt;Daily Wildcat&lt;/a&gt; of the
&lt;a href=&#34;https://arizona.edu&#34;&gt;University of Arizona&lt;/a&gt; (UArizona) has routinely provided
the salary of UArizona employees for nearly a decade through public requests.
While this allowed for the easy viewing of information for an individual,
the analysis from the Daily Wildcat was rather limited. As such, I wanted to
build a data visualization app that allow anyone to explore the data for
100% transparency.&lt;/p&gt;
&lt;h2 id=&#34;how&#34;&gt;How&lt;/h2&gt;
&lt;p&gt;The salary data were available as machine-readable CSV files, so it made sense
to build a Python application that uses &lt;code&gt;pandas&lt;/code&gt; to extract, transform, and
load (ETL) the data. I heard about &lt;code&gt;streamlit&lt;/code&gt;, a Python web framework that
would make it faster to build such an app. Essentially &lt;code&gt;streamlit&lt;/code&gt; provides a
RESTful application programming interface (API) with a front-end layer that
interacts with Python scripts that do data analysis and visualization. It
took me about a weekend to understand &lt;code&gt;streamlit&lt;/code&gt; and its &amp;ldquo;widgets&amp;rdquo;, which
are interactive tools that could be used to perform ETL actions with the data.
From there, I put together the software to load the data and provide different
&amp;ldquo;data views&amp;rdquo; that were different interactions with the data. The code is
available on &lt;a href=&#34;https://www.github.com/astrochun/uarizona-salary-app&#34;&gt;GitHub&lt;/a&gt;
under an MIT License. There are many resources and blogs about building a
&lt;code&gt;streamlit&lt;/code&gt;, so I won&#39;t go in details here, but I will illustrate some
aspects:&lt;/p&gt;
&lt;p&gt;Loading in data can be simple.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import pandas as pd
import streamlit as st

# List of fiscal years
FY_LIST = [
    &#39;FY2019-20&#39;, &#39;FY2018-19&#39;, &#39;FY2017-18&#39;, &#39;FY2016-17&#39;,
    &#39;FY2014-15&#39;, &#39;FY2013-14&#39;, &#39;FY2011-12&#39;,
]


@st.cache
def load_data():

    file_id = {
        &#39;FY2019-20&#39;: &#39;1d2l29_T-mOh05bglPlwAFlzeV1PIkRXd&#39;,
        &#39;FY2018-19&#39;: &#39;1paxrUyW1wZuK3bjSL_L7ckKEC6xslZJe&#39;,
        &#39;FY2017-18&#39;: &#39;1AnRaPpbRTLVyqdeqe6vkPMYgbNnw9zia&#39;,
        &#39;FY2016-17&#39;: &#39;1rXBuuXit5oWKtfnA05gsNtsWAyESeIs2&#39;,
        &#39;FY2014-15&#39;: &#39;1ZANVDr6Kw40MJYiOENWbLMTFEMWyf7f4&#39;,
        &#39;FY2013-14&#39;: &#39;1rQ8A2CIVhDYu0lESKVh72h6VUd8gIEFl&#39;,
        &#39;FY2011-12&#39;: &#39;1fQOzEHiOvc_H1NcLMlK3KVV1DJkRbRuX&#39;,
    }

    data_dict = {}
    for year in FY_LIST:
        data_dict[year] = pd.read_csv(
            f&#39;https://drive.google.com/uc?id={file_id[year]}&#39;
        )

    return data_dict


def main():

    # Load data
    data_dict = load_data()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code loads every previous year&#39;s of available data into a &lt;code&gt;dict&lt;/code&gt;
of &lt;code&gt;pandas&lt;/code&gt; DataFrames. The &lt;code&gt;st.cache&lt;/code&gt; decorator ensures that the data is
loaded into memory once. This ensures a shorter response time when it&#39;s
deployed and users are accessing the app frequently. Here, I made the data
publicly available in Google Drive. I could have gone with an SQL server,
but given the  small record sizes (~10,000 records), and the reliability
of Google Drive, this worked well for an MVP.&lt;/p&gt;
&lt;p&gt;To select from the data, I utilized &lt;code&gt;streamlit&lt;/code&gt; sidebar widgets to add the
layer for selection. For example, the following selects the data for one
fiscal year:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def select_fiscal_year() -&amp;gt; str:
    &amp;quot;&amp;quot;&amp;quot;Sidebar widget to select fiscal year&amp;quot;&amp;quot;&amp;quot;

    st.sidebar.markdown(&#39;### Select fiscal year:&#39;)
    fy_select = st.sidebar.selectbox(&#39;&#39;, FY_LIST, index=0).split(&#39; &#39;)[0]

    return fy_select


def main():
    # Load data
    data_dict = load_data()

    fy_select = select_fiscal_year()

    # Select dataframe
    df = data_dict[fy_select]
    st.sidebar.text(f&amp;quot;{fy_select} data imported!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This results in something that looks like this:&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;screenshot1.png&#34; data-caption=&#34;Sidebar tool selection for fiscal year&#34;&gt;
&lt;img src=&#34;screenshot1.png&#34; alt=&#34;&#34; width=&#34;40%&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Sidebar tool selection for fiscal year
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;As discussed earlier, interactions with the data is done with different views.
Currently, I have six of them:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Trends: General facts and numbers (e.g. number of employees, salary budget), for each fiscal year&lt;/li&gt;
&lt;li&gt;Salary Summary: Statistics and percentile salary data, includes salary histogram&lt;/li&gt;
&lt;li&gt;Highest Earners: Extract data above a minimum salary&lt;/li&gt;
&lt;li&gt;College/Division Data: Similar to Salary Summary but extracted for each college(s)/division(s)&lt;/li&gt;
&lt;li&gt;Department Data: Similar to Salary Summary but extracted for each department(s)&lt;/li&gt;
&lt;li&gt;Individual Search: Search for all data for individuals or by looking at each department&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This can easily be done on the sidebar and then the main page is loaded&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;DATA_VIEWS = [
    &#39;About&#39;, &#39;Individual Search (NEW)&#39;, &#39;Trends&#39;, &#39;Salary Summary&#39;,
    &#39;Highest Earners&#39;, &#39;College/Division Data&#39;, &#39;Department Data&#39;,
]

def select_data_view() -&amp;gt; str:
    &amp;quot;&amp;quot;&amp;quot;Sidebar widget to select your data view&amp;quot;&amp;quot;&amp;quot;

    st.sidebar.markdown(&#39;### Select your data view:&#39;)
    view_select = st.sidebar.selectbox(&#39;&#39;, DATA_VIEWS, index=0)

    return view_select


def main():
    # Sidebar, select data view
    view_select = select_data_view()

    if view_select == &#39;About&#39;:
        views.about_page()

    if view_select == &#39;Trends&#39;:
        views.trends_page(data_dict, pay_norm)

    if view_select == &#39;Salary Summary&#39;:
        views.salary_summary_page(df, pay_norm)

    if view_select == &#39;Highest Earners&#39;:
        views.highest_earners_page(df)

    # Select by College Name
    if view_select == &#39;College/Division Data&#39;:
        views.subset_select_data_page(df, COLLEGE_NAME, &#39;college&#39;,
                                      pay_norm)

    # Select by Department Name
    if view_select == &#39;Department Data&#39;:
        views.subset_select_data_page(df, &#39;Department&#39;, &#39;department&#39;,
                                      pay_norm)

    # Load individual search
    if view_select == &#39;Individual Search&#39;:
        views.individual_search_page(data_dict, unique_df)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here &lt;code&gt;views&lt;/code&gt; is a Python module and each of its function displays
different  content in the main page. Here&#39;s a screenshot for the
Salary Summary page&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;screenshot2.png&#34; data-caption=&#34;One of the data views from sapp4ua.&#34;&gt;
&lt;img src=&#34;screenshot2.png&#34; alt=&#34;&#34; width=&#34;100%&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    One of the data views from &lt;code&gt;sapp4ua&lt;/code&gt;.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;newest-feature&#34;&gt;Newest feature!&lt;/h2&gt;
&lt;p&gt;Recently &lt;a href=&#34;https://twitter.com/astrochunly/status/1407485898485239809&#34;&gt;I asked users what the next key feature&lt;/a&gt;
they would like to see. With 40% of the vote, users felt that having a search
tool to look at individual salary would be key.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;.&lt;a href=&#34;https://twitter.com/uarizona?ref_src=twsrc%5Etfw&#34;&gt;@uarizona&lt;/a&gt; salary app is all about the experience of the users, so help me prioritize what&amp;#39;s the next ðŸ˜Ž feature for ðŸš€!&lt;a href=&#34;https://t.co/sPs8xmkTbz&#34;&gt;https://t.co/sPs8xmkTbz&lt;/a&gt;&lt;a href=&#34;https://twitter.com/CAJUArizona?ref_src=twsrc%5Etfw&#34;&gt;@CAJUArizona&lt;/a&gt; &lt;a href=&#34;https://twitter.com/UCWArizona?ref_src=twsrc%5Etfw&#34;&gt;@UCWArizona&lt;/a&gt; &lt;a href=&#34;https://twitter.com/coba_uarizona?ref_src=twsrc%5Etfw&#34;&gt;@coba_uarizona&lt;/a&gt;&lt;/p&gt;&amp;mdash; Chun Ly, Ph.D. (@astrochunly) &lt;a href=&#34;https://twitter.com/astrochunly/status/1407485898485239809?ref_src=twsrc%5Etfw&#34;&gt;June 22, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;This data view is now available and even has the option to search
for all individuals in a department.&lt;/p&gt;
&lt;h2 id=&#34;whats-next&#34;&gt;What&#39;s next?&lt;/h2&gt;
&lt;h4 id=&#34;more-data-views&#34;&gt;More data views!&lt;/h4&gt;
&lt;p&gt;In 2020, UArizona completed the
&lt;a href=&#34;https://hr.arizona.edu/content/university-career-architecture-project-ucap&#34;&gt;University Career Architecture Project (UCAP)&lt;/a&gt;,
which map every employee to specific career streams. I recently submitted
a public request for FY2020-21 data that includes UCAP and other
demographics (e.g. sex, race, ethnicity). In fact,
&lt;a href=&#34;https://twitter.com/astrochunly/status/1392310191190732802&#34;&gt;UCAP was my original motivation for this app&lt;/a&gt;.
With a proper mapping of career streams, any UArizona member could
easily compare their salary against those across the campus with the
same job responsibilities.&lt;/p&gt;
&lt;p&gt;Once I have these data, I&#39;ll then add additional views to explore
the UCAP classification and other demographics.&lt;/p&gt;
&lt;h2 id=&#34;support-it&#34;&gt;Support it!&lt;/h2&gt;
&lt;p&gt;If you found this &lt;strong&gt;open-source&lt;/strong&gt; software useful, consider sponsoring me
through GitHub with a small donation. Your name will be included as a sponsor
on the app&#39;s main page&lt;/p&gt;
&lt;iframe src=&#34;https://github.com/sponsors/astrochun/button&#34;
title=&#34;Sponsor astrochun&#34; height=&#34;35&#34; width=&#34;116&#34; style=&#34;border: 0;&#34;&gt;
&lt;/iframe&gt;
</description>
    </item>
    
  </channel>
</rss>
